{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "627e1c46-245f-44c0-a1e8-5e32524613f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c482d6af-b3a9-4862-91e7-658c63901eb0",
   "metadata": {},
   "source": [
    "# Carga de corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8d5f54d-fd58-47e9-b012-52e27d20aac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>categoría</th>\n",
       "      <th>sentimiento</th>\n",
       "      <th>tokens</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>review_length</th>\n",
       "      <th>cleaned_reviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2VGK9S4DKTMF</td>\n",
       "      <td>B002V9X78U</td>\n",
       "      <td>BWallace</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>Let's be clear; I love how much I hate this pr...</td>\n",
       "      <td>1</td>\n",
       "      <td>Lame, even for a white elephant gift</td>\n",
       "      <td>1386720000</td>\n",
       "      <td>2013-12-11</td>\n",
       "      <td>beauty</td>\n",
       "      <td>0</td>\n",
       "      <td>['lets', 'clear', 'love', 'much', 'hate', 'pro...</td>\n",
       "      <td>lets clear love much hate product bought white...</td>\n",
       "      <td>121</td>\n",
       "      <td>let clear love much hate product bought white ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1N2EONG2Y6NUZ</td>\n",
       "      <td>B0001EL5R2</td>\n",
       "      <td>Shana</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>This made my skin so greasy and shiny, in addi...</td>\n",
       "      <td>1</td>\n",
       "      <td>Hello greasy skin!</td>\n",
       "      <td>1373587200</td>\n",
       "      <td>2013-07-12</td>\n",
       "      <td>beauty</td>\n",
       "      <td>0</td>\n",
       "      <td>['made', 'skin', 'greasy', 'shiny', 'addition'...</td>\n",
       "      <td>made skin greasy shiny addition helping acne d...</td>\n",
       "      <td>23</td>\n",
       "      <td>made skin greasy shiny addition helping acne d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ANWZD7ZYE50UE</td>\n",
       "      <td>B005MZS03C</td>\n",
       "      <td>Gilberto Prieto</td>\n",
       "      <td>[0, 5]</td>\n",
       "      <td>i receive the perfume today and they are fake ...</td>\n",
       "      <td>1</td>\n",
       "      <td>FAKE!!!</td>\n",
       "      <td>1379894400</td>\n",
       "      <td>2013-09-23</td>\n",
       "      <td>beauty</td>\n",
       "      <td>0</td>\n",
       "      <td>['receive', 'perfume', 'today', 'fake', 'also'...</td>\n",
       "      <td>receive perfume today fake also bought gucci g...</td>\n",
       "      <td>40</td>\n",
       "      <td>receive perfume today fake also bought gucci g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A20RM3LL5IW5JO</td>\n",
       "      <td>B003UZ4R24</td>\n",
       "      <td>Oulzo</td>\n",
       "      <td>[2, 7]</td>\n",
       "      <td>I got excited after seeing the multiple videos...</td>\n",
       "      <td>1</td>\n",
       "      <td>Do not buy, the mask is full of alcohol!!!!!!!</td>\n",
       "      <td>1389398400</td>\n",
       "      <td>2014-01-11</td>\n",
       "      <td>beauty</td>\n",
       "      <td>0</td>\n",
       "      <td>['got', 'excited', 'seeing', 'multiple', 'vide...</td>\n",
       "      <td>got excited seeing multiple videos youtube hea...</td>\n",
       "      <td>237</td>\n",
       "      <td>got excited seeing multiple video youtube heav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A3E3GD3TABXKU1</td>\n",
       "      <td>B0017TZD7S</td>\n",
       "      <td>Loren w Christensen</td>\n",
       "      <td>[2, 5]</td>\n",
       "      <td>Maybe I don't get the point with this. Okay, t...</td>\n",
       "      <td>2</td>\n",
       "      <td>don't get its purpose</td>\n",
       "      <td>1215734400</td>\n",
       "      <td>2008-07-11</td>\n",
       "      <td>beauty</td>\n",
       "      <td>0</td>\n",
       "      <td>['maybe', 'dont', 'get', 'point', 'okay', 'use...</td>\n",
       "      <td>maybe dont get point okay use sex sell get sup...</td>\n",
       "      <td>165</td>\n",
       "      <td>maybe dont get point okay use sex sell get sup...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin         reviewerName helpful  \\\n",
       "0   A2VGK9S4DKTMF  B002V9X78U             BWallace  [1, 1]   \n",
       "1  A1N2EONG2Y6NUZ  B0001EL5R2                Shana  [0, 0]   \n",
       "2   ANWZD7ZYE50UE  B005MZS03C      Gilberto Prieto  [0, 5]   \n",
       "3  A20RM3LL5IW5JO  B003UZ4R24                Oulzo  [2, 7]   \n",
       "4  A3E3GD3TABXKU1  B0017TZD7S  Loren w Christensen  [2, 5]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  Let's be clear; I love how much I hate this pr...        1   \n",
       "1  This made my skin so greasy and shiny, in addi...        1   \n",
       "2  i receive the perfume today and they are fake ...        1   \n",
       "3  I got excited after seeing the multiple videos...        1   \n",
       "4  Maybe I don't get the point with this. Okay, t...        2   \n",
       "\n",
       "                                          summary  unixReviewTime  reviewTime  \\\n",
       "0            Lame, even for a white elephant gift      1386720000  2013-12-11   \n",
       "1                              Hello greasy skin!      1373587200  2013-07-12   \n",
       "2                                         FAKE!!!      1379894400  2013-09-23   \n",
       "3  Do not buy, the mask is full of alcohol!!!!!!!      1389398400  2014-01-11   \n",
       "4                           don't get its purpose      1215734400  2008-07-11   \n",
       "\n",
       "  categoría  sentimiento                                             tokens  \\\n",
       "0    beauty            0  ['lets', 'clear', 'love', 'much', 'hate', 'pro...   \n",
       "1    beauty            0  ['made', 'skin', 'greasy', 'shiny', 'addition'...   \n",
       "2    beauty            0  ['receive', 'perfume', 'today', 'fake', 'also'...   \n",
       "3    beauty            0  ['got', 'excited', 'seeing', 'multiple', 'vide...   \n",
       "4    beauty            0  ['maybe', 'dont', 'get', 'point', 'okay', 'use...   \n",
       "\n",
       "                                        cleaned_text  review_length  \\\n",
       "0  lets clear love much hate product bought white...            121   \n",
       "1  made skin greasy shiny addition helping acne d...             23   \n",
       "2  receive perfume today fake also bought gucci g...             40   \n",
       "3  got excited seeing multiple videos youtube hea...            237   \n",
       "4  maybe dont get point okay use sex sell get sup...            165   \n",
       "\n",
       "                                  cleaned_reviewText  \n",
       "0  let clear love much hate product bought white ...  \n",
       "1  made skin greasy shiny addition helping acne d...  \n",
       "2  receive perfume today fake also bought gucci g...  \n",
       "3  got excited seeing multiple video youtube heav...  \n",
       "4  maybe dont get point okay use sex sell get sup...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corpus = pd.read_csv('df_corpus.csv')\n",
    "df_corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bc3a55-8df2-41c6-85e5-2d335d439690",
   "metadata": {},
   "source": [
    "# Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49624cc2-a9e6-4f25-9b1c-fb50ac7f2b8e",
   "metadata": {},
   "source": [
    "## División de muestra en train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "732a59a4-b44c-4cc5-ab34-845cde60f5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de clases en el conjunto de entrenamiento:\n",
      "sentimiento\n",
      "1    0.5\n",
      "0    0.5\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "y = df_corpus['sentimiento']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_corpus['cleaned_reviewText'], y, test_size=0.2, random_state=42, shuffle=True, stratify=y)\n",
    "\n",
    "print(\"Distribución de clases en el conjunto de entrenamiento:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "\n",
    "# Vamos a vectorizar usando TfidfVectorizer \n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=15000, ngram_range=(1, 2))  \n",
    "X_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011788e7-b5df-44b0-ba50-02d8fcd3e51a",
   "metadata": {},
   "source": [
    "## Entrenamos con Naive Bayes y Regresión Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c40ceb7-4c85-48b8-abc3-da79b02cd25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo Naive Bayes\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "y_pred_nb = nb_model.predict(X_test)\n",
    "\n",
    "# Modelo Regresión Logística\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr_model.fit(X_train, y_train)\n",
    "y_pred_lr = lr_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f2e582-10f5-4c2f-94c3-c6a905d20cd6",
   "metadata": {},
   "source": [
    "## Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81d4281a-1eb0-45f6-95fa-470780708567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados del modelo Naive Bayes:\n",
      "Accuracy: 0.8346\n",
      "Precision: 0.8373\n",
      "Recall: 0.8306\n",
      "F1 Score: 0.8339\n",
      "Resultados del modelo Regresión Logística:\n",
      "Accuracy: 0.8446\n",
      "Precision: 0.8509\n",
      "Recall: 0.8356\n",
      "F1 Score: 0.8432\n"
     ]
    }
   ],
   "source": [
    "def print_metrics(y_true, y_pred, model_name):\n",
    "    print(f\"Resultados del modelo {model_name}:\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_true, y_pred):.4f}\")\n",
    "    print(f\"Precision: {precision_score(y_true, y_pred):.4f}\")\n",
    "    print(f\"Recall: {recall_score(y_true, y_pred):.4f}\")\n",
    "    print(f\"F1 Score: {f1_score(y_true, y_pred):.4f}\")\n",
    "\n",
    "print_metrics(y_test, y_pred_nb, \"Naive Bayes\")\n",
    "\n",
    "print_metrics(y_test, y_pred_lr, \"Regresión Logística\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5eac1db5-f368-46d5-9920-5a4ca351f406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voy a guardar las predicciones para el siguiente paso donde haremos un reporte de métricas\n",
    "\n",
    "predictions_df = pd.DataFrame({\n",
    "    'true_labels': y_test,\n",
    "    'nb_predictions': y_pred_nb,\n",
    "    'lr_predictions': y_pred_lr\n",
    "})\n",
    "\n",
    "predictions_df.to_csv('model_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf422ad-66f0-4f43-859d-d725249ddb6b",
   "metadata": {},
   "source": [
    "# Primeras conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fb1915-bb69-416a-8b7b-c2a4d2d84b57",
   "metadata": {},
   "source": [
    "- A priori, la Regresión Logística parece dar mejores resultados que Naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4234e591-8e72-49c4-aad6-14c248373bc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
